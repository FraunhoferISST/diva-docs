"use strict";(self.webpackChunkdiva_docs=self.webpackChunkdiva_docs||[]).push([[8606],{3905:function(e,t,a){a.d(t,{Zo:function(){return m},kt:function(){return u}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var c=n.createContext({}),l=function(e){var t=n.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=l(e.components);return n.createElement(c.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,c=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),d=l(a),u=r,p=d["".concat(c,".").concat(u)]||d[u]||h[u]||i;return a?n.createElement(p,o(o({ref:t},m),{},{components:a})):n.createElement(p,o({ref:t},m))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=d;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var l=2;l<i;l++)o[l]=a[l];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},9048:function(e,t,a){a.r(t),a.d(t,{assets:function(){return m},contentTitle:function(){return c},default:function(){return u},frontMatter:function(){return s},metadata:function(){return l},toc:function(){return h}});var n=a(7462),r=a(3366),i=(a(7294),a(3905)),o=["components"],s={id:"json-schemas",title:"Schemata"},c=void 0,l={unversionedId:"Development/Architecture/json-schemas",id:"Development/Architecture/json-schemas",title:"Schemata",description:"To ensure high level of integrity and validity during write operations to the data storage and exchange of Kafka messages, we use JSON Schemas and AsyncAPI accordingly.",source:"@site/docs/04-Development/04-Architecture/02-json-schemas.md",sourceDirName:"04-Development/04-Architecture",slug:"/Development/Architecture/json-schemas",permalink:"/diva-docs/docs/next/Development/Architecture/json-schemas",draft:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"json-schemas",title:"Schemata"},sidebar:"divaSidebar",previous:{title:"Overview",permalink:"/diva-docs/docs/next/Development/Architecture/introduction"},next:{title:"REST API",permalink:"/diva-docs/docs/next/Development/Architecture/rest-api"}},m={},h=[{value:"JSON Schema",id:"json-schema",level:2},{value:"Defining a Schema",id:"defining-a-schema",level:3},{value:"Validation",id:"validation",level:3}],d={toc:h};function u(e){var t=e.components,a=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"To ensure high level of integrity and validity during write operations to the data storage and exchange of Kafka messages, we use ",(0,i.kt)("a",{parentName:"p",href:"https://json-schema.org/"},"JSON Schemas")," and ",(0,i.kt)("a",{parentName:"p",href:"https://www.asyncapi.com/"},"AsyncAPI")," accordingly."),(0,i.kt)("h2",{id:"json-schema"},"JSON Schema"),(0,i.kt)("p",null,"JSON schemas are the fundamental building block of the whole DIVA architecture.\nIn Diva 2 we have implemented a granular structured hierarchical schema system that has saved us a lot of unnecessary complexity and hundreds lines of code compared to DIVA 1."),(0,i.kt)("p",null,"Every existing piece of data in DIVA is well defined in a schema.\nDIVA never accepts data that is not explicitly defined in a schema.\nThis in turn means that schemas are the first place in the system to be tweaked when developing new functionality.\nSchema-drive development engages us to first clearly define the data model and then start with implementation.\nHowever, the most important benefit comes from the fact that thanks to the JSON Schema tools we were able to implement fully automated validation of the data in our services."),(0,i.kt)("p",null,"You will find all the schemas ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/FraunhoferISST/diva/tree/main/core/services/entity-management/defaultEntities/jsonSchemata"},"here"),".\nJSON schema determine our ",(0,i.kt)("a",{parentName:"p",href:"../architecture/introduction#data-model"},"data model"),'.\nSince the attributes of different resource types can vary significantly, we define other sub-resources such as PDF, CSV, PNG, etc. for the resources and assets.\nThe type of sub-resource is generally determined by the format or type of data source.\nE.g. MongoDB, Hadoop or an API could be a sub-resource.\nThe entity abstracts common attributes that are "inherited" by all other entities.'),(0,i.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"Top-to-Bottom schemas")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"Practically, we define the schemas using the top-to-bottom approach.\nThis means that we extend from a parent schema called ",(0,i.kt)("inlineCode",{parentName:"p"},"entity"),".\nEvery other entity is underneath the entity schema."))),(0,i.kt)("p",null,"With thisapproach, we include the subordinated schemas in the master schema according to certain conditions.\nBasically, for example, the resource schema contains all the schemas definition of the sub-resources.\nThe advantages of this way of constructing the schemas are especially evident in automated validation."),(0,i.kt)("h3",{id:"defining-a-schema"},"Defining a Schema"),(0,i.kt)("p",null,"The biggest disadvantage of schemas - they must be written.\nThe important thing to note here is that each attribute has a strict and detailed definition.\nAnd as mentioned before, every possible piece of data must be described in a schema, whether it is a resource, user, etc.\nWe already have a user interface to generate new fields and thus schemas ",(0,i.kt)("a",{parentName:"p",href:"../../user-docs/admin/field-generator"},"here"),".\nWe will demonstrate the process of schema creation using a new field for a resource."),(0,i.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"This part will be updated soon..."))),(0,i.kt)("h3",{id:"validation"},"Validation"),(0,i.kt)("p",null,"There are many different tools in the JSON Schema ecosystem.\nFor validating the data against a schema we use ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/ajv-validator/ajv"},"ajv")," library for Node.js.\nWe recommend the use of similar tools for your programming language."),(0,i.kt)("p",null,"Generally all write operations to the main MongoDB storage must pass validation first.\nSo all management services must always implement the validation.\nThe management services like Resource or User Management fetch the required schema on a start time from the Schema Registry service.\nImportant to note that the services have only to fetch the root schema (e.g. ",(0,i.kt)("inlineCode",{parentName:"p"},"resource.json")," or ",(0,i.kt)("inlineCode",{parentName:"p"},"user.json"),") thanks to the top-to-bottom approach and automated schema resolution in ajv.\nThe services with read-only access to the entities can implement the validation, but do not have to."))}u.isMDXComponent=!0}}]);